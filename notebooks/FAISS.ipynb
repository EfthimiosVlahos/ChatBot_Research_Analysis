{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18a15ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.6.0 from https://files.pythonhosted.org/packages/98/46/f6a79f944d5c7763a9bc13b2aa6ac72daf43a6551f5fb03bccf0a9c2fec1/transformers-4.33.3-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.33.3-py3-none-any.whl.metadata (119 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers)\n",
      "  Using cached torch-2.0.1-cp310-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from sentence-transformers) (1.26.0)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/68/43/5f371523089871c0190800d64a9483f86ae68cd8360a86f529596b3a0496/scikit_learn-1.3.1-cp310-cp310-macosx_12_0_arm64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/62/35/4297fb91ee65883caa6c228eb8ae27db0a41353819902694c61d3bd22de1/scipy-1.11.3-cp310-cp310-macosx_12_0_arm64.whl.metadata\n",
      "  Using cached scipy-1.11.3-cp310-cp310-macosx_12_0_arm64.whl.metadata (112 kB)\n",
      "Requirement already satisfied: nltk in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Collecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for huggingface-hub>=0.4.0 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.4.0->sentence-transformers)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/5e/5d/97afbafd9d584ff1b45fcb354a479a3609bd97f912f8f1f6c563cb1fae21/filelock-3.12.4-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec (from huggingface-hub>=0.4.0->sentence-transformers)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/fe/d3/e1aa96437d944fbb9cc95d0316e25583886e9cd9e6adc07baad943524eda/fsspec-2023.9.2-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: requests in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Collecting sympy (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl (3.9 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/78/e9/cb767f6e389683ceb7da564fd9e8424467562ed81ef5dff5895badad39d9/safetensors-0.3.3-cp310-cp310-macosx_13_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-macosx_13_0_arm64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: click in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached scikit_learn-1.3.1-cp310-cp310-macosx_12_0_arm64.whl (9.5 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached scipy-1.11.3-cp310-cp310-macosx_12_0_arm64.whl (29.8 MB)\n",
      "Downloading safetensors-0.3.3-cp310-cp310-macosx_13_0_arm64.whl (406 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.9/406.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=69c093f15a9cfd80705076f053f47e616b800069c123a6de9a484c052973b7b5\n",
      "  Stored in directory: /Users/Vlahonator/Library/Caches/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, mpmath, threadpoolctl, sympy, scipy, networkx, fsspec, filelock, torch, scikit-learn, huggingface-hub, transformers, torchvision, sentence-transformers\n",
      "Successfully installed filelock-3.12.4 fsspec-2023.9.2 huggingface-hub-0.17.3 mpmath-1.3.0 networkx-3.1 safetensors-0.3.3 scikit-learn-1.3.1 scipy-1.11.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 threadpoolctl-3.2.0 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.33.3\n"
     ]
    }
   ],
   "source": [
    "#Install Packages\n",
    "!pip install faiss-cpu\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7185d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b4872a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sample_text.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa57df6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meditation and yoga can improve mental health</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fruits, whole grains and vegetables helps control blood pressure</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These are the latest fashion trends for this week</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vibrant color jeans for male are becoming a trend</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The concert starts at 7 PM tonight</td>\n",
       "      <td>Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Navaratri dandiya program at Expo center in Mumbai this october</td>\n",
       "      <td>Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Exciting vacation destinations for your next trip</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maldives and Srilanka are gaining popularity in terms of low budget vacation places</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  text  \\\n",
       "0                                        Meditation and yoga can improve mental health   \n",
       "1                     Fruits, whole grains and vegetables helps control blood pressure   \n",
       "2                                    These are the latest fashion trends for this week   \n",
       "3                                    Vibrant color jeans for male are becoming a trend   \n",
       "4                                                   The concert starts at 7 PM tonight   \n",
       "5                      Navaratri dandiya program at Expo center in Mumbai this october   \n",
       "6                                    Exciting vacation destinations for your next trip   \n",
       "7  Maldives and Srilanka are gaining popularity in terms of low budget vacation places   \n",
       "\n",
       "  category  \n",
       "0   Health  \n",
       "1   Health  \n",
       "2  Fashion  \n",
       "3  Fashion  \n",
       "4    Event  \n",
       "5    Event  \n",
       "6   Travel  \n",
       "7   Travel  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9f9a3",
   "metadata": {},
   "source": [
    "## Step 1 : Create source embeddings for the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9febe2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Vlahonator/anaconda3/envs/nlp_envir/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0863f54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)a8e1d/.gitattributes: 100%|█████████████████| 1.18k/1.18k [00:00<00:00, 1.16MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|█████████████████████| 190/190 [00:00<00:00, 1.60MB/s]\n",
      "Downloading (…)b20bca8e1d/README.md: 100%|█████████████████| 10.6k/10.6k [00:00<00:00, 47.0MB/s]\n",
      "Downloading (…)0bca8e1d/config.json: 100%|█████████████████████| 571/571 [00:00<00:00, 3.86MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████████████████| 116/116 [00:00<00:00, 282kB/s]\n",
      "Downloading (…)e1d/data_config.json: 100%|█████████████████| 39.3k/39.3k [00:00<00:00, 26.2MB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████████████████████| 438M/438M [00:40<00:00, 10.7MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|████████████████████| 53.0/53.0 [00:00<00:00, 122kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|█████████████████████| 239/239 [00:00<00:00, 1.11MB/s]\n",
      "Downloading (…)a8e1d/tokenizer.json: 100%|███████████████████| 466k/466k [00:00<00:00, 11.4MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|█████████████████████| 363/363 [00:00<00:00, 1.97MB/s]\n",
      "Downloading (…)8e1d/train_script.py: 100%|█████████████████| 13.1k/13.1k [00:00<00:00, 29.4MB/s]\n",
      "Downloading (…)b20bca8e1d/vocab.txt: 100%|███████████████████| 232k/232k [00:00<00:00, 17.2MB/s]\n",
      "Downloading (…)bca8e1d/modules.json: 100%|██████████████████████| 349/349 [00:00<00:00, 986kB/s]\n"
     ]
    }
   ],
   "source": [
    "encoder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "vectors = encoder.encode(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b11122e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfa04b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00247378,  0.03626734, -0.05290457, ..., -0.0915236 ,\n",
       "        -0.03970009, -0.04330485],\n",
       "       [-0.03357262,  0.00980523, -0.03250129, ..., -0.05165472,\n",
       "         0.02245885, -0.03156187],\n",
       "       [-0.01865326, -0.04051305, -0.01235391, ...,  0.00610579,\n",
       "        -0.0717965 ,  0.02773846],\n",
       "       ...,\n",
       "       [-0.00066462,  0.04252121, -0.05645506, ...,  0.01315471,\n",
       "        -0.03183562, -0.04357661],\n",
       "       [-0.03317155,  0.03252463, -0.02484844, ...,  0.01174419,\n",
       "         0.05747125,  0.00571023],\n",
       "       [-0.00166398,  0.00413837, -0.04597078, ...,  0.02008531,\n",
       "         0.05656243, -0.00161598]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2927b589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = vectors.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e935dd8",
   "metadata": {},
   "source": [
    "## Step 2 : Build a FAISS Index for vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c84f3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78113ab9",
   "metadata": {},
   "source": [
    "## Step 3 : Normalize the source vectors (as we are using L2 distance to measure similarity) and add to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b875c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4ac5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x297ec5e90> >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0cb17",
   "metadata": {},
   "source": [
    "## Step 4 : Encode search text using same encorder and normalize the output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "752e7e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query = \"I want to buy a polo t-shirt\"\n",
    "# search_query = \"looking for places to visit during the holidays\"\n",
    "# search_query = \"An apple a day keeps the doctor away\"\n",
    "vec = encoder.encode(search_query)\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c38d52ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "svec = np.array(vec).reshape(1,-1)\n",
    "svec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a31cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss.normalize_L2(svec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe1a846",
   "metadata": {},
   "source": [
    "## Step 5: Search for similar vector in the FAISS index created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1fa33f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3844838, 1.4039094]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances, I = index.search(svec, k=2)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ace35faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6665bc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c51aeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_indices = I.tolist()[0]\n",
    "row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46e9c798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vibrant color jeans for male are becoming a trend</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These are the latest fashion trends for this week</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text category\n",
       "3  Vibrant color jeans for male are becoming a trend  Fashion\n",
       "2  These are the latest fashion trends for this week  Fashion"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[row_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac24972f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to buy a polo t-shirt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981bfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aff5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9ff60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2504f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb57aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0831d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_envir",
   "language": "python",
   "name": "nlp_envir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
